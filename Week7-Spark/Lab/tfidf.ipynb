{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caefd39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Do not edit this cell.  Your solution should use this version of termify\n",
    "\n",
    "import re\n",
    "\n",
    "stopwords = set([\"a\", \"as\", \"able\", \"about\", \"above\", \"according\", \"accordingly\",\n",
    "\t     \"across\", \"actually\", \"after\", \"afterwards\", \"again\", \"against\", \"aint\", \"all\", \"allow\",\n",
    "\t     \"allows\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\", \"am\", \"among\",\n",
    "\t     \"amongst\", \"an\", \"and\", \"another\", \"any\", \"anybody\", \"anyhow\", \"anyone\", \"anything\", \"anyway\",\n",
    "\t     \"anyways\", \"anywhere\", \"apart\", \"appear\",\"appreciate\", \"appropriate\", \"are\", \"arent\", \"around\",\n",
    "\t     \"as\", \"aside\", \"ask\", \"asking\", \"associated\", \"at\", \"available\", \"away\", \"awfully\", \"be\", \"became\",\n",
    "\t     \"because\", \"become\", \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\",\n",
    "\t     \"being\", \"believe\", \"below\", \"beside\", \"besides\", \"best\", \"better\", \"between\", \"beyond\",\n",
    "\t     \"both\", \"brief\", \"but\", \"by\", \"cmon\", \"cs\", \"came\", \"can\", \"cant\", \"cannot\", \"cant\",\n",
    "\t     \"cause\", \"causes\", \"certain\", \"certainly\", \"changes\", \"clearly\", \"co\", \"com\", \"come\",\n",
    "\t     \"comes\", \"concerning\", \"consequently\", \"consider\", \"considering\", \"contain\", \"containing\",\n",
    "\t     \"contains\", \"corresponding\", \"could\", \"couldnt\", \"course\", \"currently\", \"definitely\",\n",
    "\t     \"described\", \"despite\", \"did\", \"didnt\", \"different\", \"do\", \"does\", \"doesnt\", \"doing\",\n",
    "\t     \"dont\", \"done\", \"down\", \"downwards\", \"during\", \"each\", \"edu\", \"eg\", \"eight\", \"either\",\n",
    "\t     \"else\", \"elsewhere\", \"enough\", \"entirely\", \"especially\", \"et\", \"etc\", \"even\", \"ever\",\n",
    "\t     \"every\", \"everybody\", \"everyone\", \"everything\", \"everywhere\", \"ex\", \"exactly\", \"example\",\n",
    "\t     \"except\", \"far\", \"few\", \"ff\", \"fifth\", \"first\", \"five\", \"followed\", \"following\", \"follows\",\n",
    "\t     \"for\", \"former\", \"formerly\", \"forth\", \"four\", \"from\", \"further\", \"furthermore\", \"get\",\n",
    "\t     \"gets\", \"getting\", \"given\", \"gives\", \"go\", \"goes\", \"going\", \"gone\", \"got\", \"gotten\",\n",
    "\t     \"greetings\", \"had\", \"hadnt\", \"happens\", \"hardly\", \"has\", \"hasnt\", \"have\", \"havent\",\n",
    "\t     \"having\", \"he\", \"hes\", \"hello\", \"help\", \"hence\", \"her\", \"here\", \"heres\", \"hereafter\",\n",
    "\t     \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"hi\", \"him\", \"himself\",\n",
    "\t     \"his\", \"hither\", \"hopefully\", \"how\", \"howbeit\", \"however\", \"i\", \"id\", \"ill\", \"im\", \"ive\",\n",
    "\t     \"ie\", \"if\", \"ignored\", \"immediate\", \"in\", \"inasmuch\", \"inc\", \"indeed\", \"indicate\",\n",
    "\t     \"indicated\", \"indicates\", \"inner\", \"insofar\", \"instead\", \"into\", \"inward\", \"is\",\n",
    "\t     \"isnt\", \"it\", \"itd\", \"itll\", \"its\", \"its\", \"itself\", \"just\", \"keep\", \"keeps\", \"kept\",\n",
    "\t     \"know\", \"knows\", \"known\", \"last\", \"lately\", \"later\", \"latter\", \"latterly\", \"least\",\n",
    "\t     \"less\", \"lest\", \"let\", \"lets\", \"like\", \"liked\", \"likely\", \"little\", \"look\", \"looking\",\n",
    "\t     \"looks\", \"ltd\", \"mainly\", \"many\", \"may\", \"maybe\", \"me\", \"mean\", \"meanwhile\", \"merely\",\n",
    "\t     \"might\", \"more\", \"moreover\", \"most\", \"mostly\", \"much\", \"must\", \"my\", \"myself\",\n",
    "\t     \"name\", \"namely\", \"nd\", \"near\", \"nearly\", \"necessary\", \"need\", \"needs\", \"neither\",\n",
    "\t     \"never\", \"nevertheless\", \"new\", \"next\", \"nine\", \"no\", \"nobody\", \"non\", \"none\", \"noone\",\n",
    "\t     \"nor\", \"normally\", \"not\", \"nothing\", \"novel\", \"now\", \"nowhere\", \"obviously\", \"of\",\n",
    "\t     \"off\", \"often\", \"oh\", \"ok\", \"okay\", \"old\", \"on\", \"once\", \"one\", \"ones\", \"only\",\n",
    "\t     \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"ought\", \"our\", \"ours\", \"ourselves\",\n",
    "\t     \"out\", \"outside\", \"over\", \"overall\", \"own\", \"particular\", \"particularly\",\n",
    "\t     \"per\", \"perhaps\", \"placed\", \"please\", \"plus\", \"possible\", \"presumably\", \"probably\",\n",
    "\t     \"provides\", \"que\", \"quite\", \"qv\", \"rather\", \"rd\", \"re\", \"really\", \"reasonably\",\n",
    "\t     \"regarding\", \"regardless\", \"regards\", \"relatively\", \"respectively\", \"right\", \"said\",\n",
    "\t     \"same\", \"saw\", \"say\", \"saying\", \"says\", \"second\", \"secondly\", \"see\", \"seeing\",\n",
    "\t     \"seem\", \"seemed\", \"seeming\", \"seems\", \"seen\", \"self\", \"selves\", \"sensible\", \"sent\",\n",
    "\t     \"serious\", \"seriously\", \"seven\", \"several\", \"shall\", \"she\", \"should\", \"shouldnt\",\n",
    "\t     \"since\", \"six\", \"so\", \"some\", \"somebody\", \"somehow\", \"someone\", \"something\",\n",
    "\t     \"sometime\", \"sometimes\", \"somewhat\", \"somewhere\", \"soon\", \"sorry\", \"specified\", \"specify\",\n",
    "\t     \"specifying\", \"still\", \"sub\", \"such\", \"sup\", \"sure\", \"ts\", \"take\", \"taken\", \"tell\", \"tends\",\n",
    "\t     \"th\", \"than\", \"thank\", \"thanks\", \"thanx\", \"that\", \"thats\", \"thats\", \"the\", \"their\", \"theirs\",\n",
    "\t     \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"theres\", \"thereafter\", \"thereby\",\n",
    "\t     \"therefore\", \"therein\", \"theres\", \"thereupon\", \"these\", \"they\", \"theyd\",\n",
    "\t     \"theyll\", \"theyre\", \"theyve\", \"think\", \"third\", \"this\", \"thorough\",\n",
    "\t     \"thoroughly\", \"those\", \"though\", \"three\", \"through\", \"throughout\", \"thru\",\n",
    "\t     \"thus\", \"to\", \"together\", \"too\", \"took\", \"toward\", \"towards\", \"tried\", \"tries\",\n",
    "\t     \"truly\", \"try\", \"trying\", \"twice\", \"two\", \"un\", \"under\", \"unfortunately\",\n",
    "\t     \"unless\", \"unlikely\", \"until\", \"unto\", \"up\", \"upon\", \"us\", \"use\", \"used\",\n",
    "\t     \"useful\", \"uses\", \"using\", \"usually\", \"value\", \"various\", \"very\", \"via\", \"viz\",\n",
    "\t     \"vs\", \"want\", \"wants\", \"was\", \"wasnt\", \"way\", \"we\", \"wed\", \"well\", \"were\", \"weve\",\n",
    "\t     \"welcome\", \"well\", \"went\", \"were\", \"werent\", \"what\", \"whats\", \"whatever\", \"when\",\n",
    "\t     \"whence\", \"whenever\", \"where\", \"wheres\", \"whereafter\", \"whereas\", \"whereby\",\n",
    "\t     \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\", \"who\",\n",
    "\t     \"whos\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"willing\", \"wish\",\n",
    "\t     \"with\", \"within\", \"without\", \"wont\", \"wonder\", \"would\", \"would\", \"wouldnt\", \"yes\",\n",
    "\t     \"yet\", \"you\", \"youd\", \"youll\", \"youre\", \"youve\", \"your\", \"yours\", \"yourself\",\n",
    "\t     \"yourselves\", \"zero\"])\n",
    "\n",
    "def termify(line):\n",
    "    terms = []\n",
    "    words = re.findall(r'[^\\W_]+', line)\n",
    "    for word in words:\n",
    "        lowered = word.lower()\n",
    "        if (len(lowered) > 1) and (lowered not in stopwords) and (not re.search(r'^\\d*$', lowered)):\n",
    "            terms.append(lowered)\n",
    "    return terms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aff30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this variable to point to your S3 location for the text corpus\n",
    "books = 's3://5330books/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86529fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not edit this cell.  Use this function to get a docid from a file path\n",
    "def get_docid(filepath):\n",
    "    return filepath.split('/')[-1][: -4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4d8062",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Put your code to build your tfidf RDD in this cell\n",
    "#  Create a variable with the name tfidf for your RDD\n",
    "#  Tuples created by the rdd must be in the form ((term, docid), numeric-tfidf-value)\n",
    "\n",
    "tfidf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df8ed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not edit this cell.  This list has test data you will run against\n",
    "# your tfidf RDD\n",
    "\n",
    "sample = [('reconciliation', 'austen-persuasion'), \n",
    "          ('knives', 'chesterton-thursday'), \n",
    "          ('arm', 'milton-paradise'), \n",
    "          ('indebted', 'austen-emma'), \n",
    "          ('inspection', 'austen-emma'), \n",
    "          ('enchanting', 'whitman-leaves'), \n",
    "          ('splash', 'bryant-stories'), \n",
    "          ('decided', 'edgeworth-parents'), \n",
    "          ('material', 'melville-moby_dick'), \n",
    "          ('ashtoreth', 'bible-kjv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1f88e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# In this cell put code that \"looks up\" the TFIDF value from your RDD for \n",
    "# each term, docid pair from the sample data.  It produces a list (not and RDD) in the form as below.\n",
    "# \n",
    "# Hint -- make an RDD out of the sample array, then join against your tfidf RDD.\n",
    "#  \"Reformat\" the resulting join to get an RDD with tuples of the form below. \n",
    "#  Use collect to convert the RDD to an array\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d736f0",
   "metadata": {},
   "source": [
    "Output for sample data tfidf\n",
    "\n",
    "<pre>\n",
    "[(('indebted', 'austen-emma'), 5.059192552868563), \n",
    "  (('arm', 'milton-paradise'), 9.658243069003317), \n",
    "  (('ashtoreth', 'bible-kjv'), 3.7973289588103727), \n",
    "  (('splash', 'bryant-stories'), 3.625474030729518), \n",
    "  (('knives', 'chesterton-thursday'), 5.755958856406094), \n",
    "  (('reconciliation', 'austen-persuasion'), 8.007142370994929), \n",
    "  (('enchanting', 'whitman-leaves'), 2.7463096464126333), \n",
    "  (('material', 'melville-moby_dick'), 2.6229948515857053), \n",
    "  (('decided', 'edgeworth-parents'), 1.6429353778751368)]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad7e65a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
